# Abstract

1. 数据收集
2. 训练语言模型
	1. 题目难度分析模型
	2. 题目受欢迎程度分析模型
	3. 题目文本风格模型
		1. 二次元程度
		2. 学术程度
		3. 文学程度
		4. 上流程度
		5.  翻译腔程度
		6.  用例丰富程度
3. 使用模型分析200道python题整体情况
	1. 题目难度
	2. 题目受欢迎程度
	3. 题目文本风格
3. 使用模型评估软件学院学生
	1. 做题能力
	2. 个人偏好




# Data Collection

使用python爬虫进行数据收集，或从开放NLP数据集下载。

使用工具包

- re: 正则表达式
- request: 网页访问工具
- Beautiful Soup: 解析html和xml语法

数据来源

- 乐扣中文leetcode-cn.com
- 萌娘百科zh.moegirl.org
- 南京大学中文学术资源klss.casb.nju.edu.cn
- 中文NLP数据集www.cluebenchmarks.com
- 开源数据集www.github.com


# Exploratory Data Analysis

### leetcode数据
![YGUKz9.png](https://s1.ax1x.com/2020/05/11/YGUKz9.png)

leetcode网站上获得的信息包括

- 题目的中文描述（包括题目信息和测试用例）
- 题目的点赞数量
- 题目的难度分级（离散数据，包括“简单”“中等”“困难”）

### 其他文本数据

主要包括

- 以萌娘百科为代表的二次元文本
- 以中文著作为代表的文学文本
- 以中文学术资料为代表的学术文本

# Machine Learning

### 题目难度分析模型

关于题目难度分析，只可能是粗略的、基于渐层语义信息的分析。

如果我们的模型可以完全正确的分析任何题目的难度，这首先要求我们的模型可以将所有题目的答案写出来，这自然也包括需要**不确定多项式时间**的问题，因此我们所解决的问题可以视作这类问题的**规约**，也就是说，学习精确的模型是一个**NPC**的问题。

因此，我们不尝试训练精确的模型。

我们首先在leetcode数据集上，使用无监督学习**word2vec**实现从中文到词向量的转换。

然后使用时间序列分析LSTM进行监督学习，模型的输入是由词向量表示的问题，输出是题目的难度。这是一个监督学习问题，因为我们已经从leetcode网站获取了**人工的评分结果**。

使用工具

- gensim: NLP工具包
- jieba: 中文分词工具
- pytorch: 用于神经网络的搭建

###  题目受欢迎程度分析模型

我们将leetcode网站中的“点赞数量”作为评价题目受欢迎程度的依据。

然而，值得注意的是，leetcode网站的点赞是受时间影响的，前面的题目被更多人看到，因此点赞数量普遍较高，后面的题目被看到的次数少，因此点赞数量普遍较低，我们需要抵消这种影响。

我们使用简单的多项式回归学习出整个题目列表中，**题目编号**和**点赞数量**的关系。

注意，我们使用容量较小的模型，是为了防止过拟合，我们只想学习出大致趋势，而不认为题目编号和点赞数量有其他内在的关系。

接下来，我们用样本原本的点赞数量减去模型的预测值，作为评价题目受欢迎程度的度量。

### 题目文本风格模型

#### 二次元程度

我们用LSTM训练二分类模型，收集二次元文本和普通文本。

二次元文本来自萌娘百科，普通文本从中文语料集中采样。

我们用训练好的模型评估题目的二次元程度。

#### 学术程度

同样适用LSTM模型训练，学术文本从中文学术论文中采样。

#### 文学程度
同上。

#### 上流程度

检查题目中的词语，统计词语中出现奢侈品等昂贵物品的数目，作为评价上流程度的度量。

#### 翻译腔程度

样本来自[如何模仿翻译腔？](https://www.zhihu.com/question/24140466/answer/85033222)，检测题目中词语出现的翻译腔词语的数量，作为评价翻译腔程度的度量。

#### 用例丰富程度

以测试用例的数目作为评价标准。

# Data Visualization

使用六芒星表示题目的文本风格。

![YGDqfK.png](https://s1.ax1x.com/2020/05/11/YGDqfK.png)

# Experiment

在数据科学课程中的200道python题目中做实验。


